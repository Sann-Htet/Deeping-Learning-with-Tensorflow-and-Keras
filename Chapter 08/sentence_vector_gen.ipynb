{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decd533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image     #This is used for rendering images in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549e6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sann-htet/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package reuters to /home/sann-\n",
      "[nltk_data]     htet/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from scipy.stats import describe\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import re\n",
    "# Needed to run only once\n",
    "nltk.download('punkt')\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14573ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-30 18:30:57--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-08-30 18:30:58--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-08-30 18:30:59--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip         19%[==>                 ] 158.82M   153KB/s    eta 77m 54s"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(n):\n",
    "    temp = re.sub(\"[.,-/]\", \"\", n)\n",
    "    return temp.isdigit()\n",
    "\n",
    "# parsing sentences and building vocabulary\n",
    "word_freqs = collections.Counter()\n",
    "documents = reuters.fileids()\n",
    "#ftext = open(\"text.tsv\", \"r\")\n",
    "sents = []\n",
    "sents_lens = []\n",
    "num_read = 0\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    # periodic heartbeat report\n",
    "    if num_read % 100 == 0:\n",
    "        print(\"building features from {:d} docs\".format(num_read))\n",
    "    # skip docs without specified topic\n",
    "    title_body = reuters.raw(documents[i]).lower()\n",
    "    if len(title_body) == 0:\n",
    "        continue\n",
    "    num_read += 1\n",
    "    # convert to list of word indexes\n",
    "    title_body = re.sub(\"\\n\", \"\", title_body)\n",
    "    for sent in nltk.sent_tokenize(title_body):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if is_number(word):\n",
    "                word = \"9\"\n",
    "            word = word.lower()\n",
    "            word_freqs[word] += 1\n",
    "        sents.append(sent)\n",
    "        sent_lens.append(len(sent))\n",
    "        \n",
    "#ftext.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of sentences are: {:d} \".format(len(sents)))\n",
    "print (\"Sentence distribution min {:d}, max {:d} , mean {:3f}, median {:3f}\".format(np.min(sent_lens), np.max(sent_lens), np.mean(sent_lens), np.median(sent_lens)))\n",
    "print(\"Vocab size (full) {:d}\".format(len(word_freqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db20a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 50\n",
    "LATENT_SIZE = 512\n",
    "SEQUENCE_LEN = 50\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc05626",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "word2id[\"PAD\"] = 0\n",
    "word2id[\"UNK\"] = 1\n",
    "for v, (k, _) in enumerate(word_freqs.most_common(VOCAB_SIZE - 2)):\n",
    "    word2id[k] = v + 2\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610a7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
