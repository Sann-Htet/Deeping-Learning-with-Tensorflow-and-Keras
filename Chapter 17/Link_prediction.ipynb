{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DGLBACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.data\n",
    "import dgl.function as fn\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from dgl.nn import SAGEConv\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = g.edges()\n",
    "\n",
    "# positive edges\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "test_size = int(len(eids) * 0.2)\n",
    "val_size = int((len(eids) - test_size) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size - val_size\n",
    "\n",
    "u = u.numpy()\n",
    "v = v.numpy()\n",
    "\n",
    "test_pos_u = u[eids[0:test_size]]\n",
    "test_pos_v = v[eids[0:test_size]]\n",
    "val_pos_u = u[eids[test_size:test_size + val_size]]\n",
    "val_pos_v = v[eids[test_size:test_size + val_size]]\n",
    "train_pos_u = u[eids[test_size + val_size:]]\n",
    "train_pos_v = v[eids[test_size + val_size:]]\n",
    "\n",
    "# negative edges\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u, v)))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u = neg_u[neg_eids[:test_size]]\n",
    "test_neg_v = neg_v[neg_eids[:test_size]]\n",
    "val_neg_u = neg_u[neg_eids[test_size:test_size + val_size]]\n",
    "val_neg_v = neg_v[neg_eids[test_size:test_size + val_size]]\n",
    "train_neg_u = neg_u[neg_eids[test_size + val_size:]]\n",
    "train_neg_v = neg_v[neg_eids[test_size + val_size:]]\n",
    "\n",
    "# remove edges from training graph\n",
    "test_edges = eids[:test_size]\n",
    "val_edges = eids[test_size:test_size + val_size]\n",
    "train_edges = eids[test_size + val_size:]\n",
    "train_g = dgl.remove_edges(g, np.concatenate([test_edges, val_edges]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(tf.keras.Model):\n",
    "    def __init__(self, g, in_feats, h_feats):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.g = g\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.relu1 = tf.keras.layers.Activation(tf.nn.relu)\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "        \n",
    "    def call(self, in_feat):\n",
    "        h = self.conv1(self.g, in_feat)\n",
    "        h = self.relu1(h)\n",
    "        h = self.conv2(self.g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ebeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=g.number_of_nodes())\n",
    "val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=g.number_of_nodes())\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6771023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductPredictor(tf.keras.Model):\n",
    "    def call(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product\n",
    "            # between the source node feature 'h' and destination node\n",
    "            # feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you\n",
    "            # need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cc115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(tf.keras.Model):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(h_feats, activation=tf.nn.relu)\n",
    "        self.W2 = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def apply_edges(self, edges):\n",
    "        h = tf.concat([edges.src[\"h\"], edges.dst[\"h\"]], axis=1)\n",
    "        return {\n",
    "        \"score\": self.W2(self.W1(h))[:, 0]\n",
    "        }\n",
    "    \n",
    "    def call(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ded8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 16\n",
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "model = LinkPredictor(train_g, train_g.ndata['feat'].shape[1], HIDDEN_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fcn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "pred = DotProductPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = tf.concat([pos_score, neg_score], axis=0)\n",
    "    labels = tf.concat([\n",
    "    tf.ones(pos_score.shape[0]),\n",
    "        tf.zeros(neg_score.shape[0])\n",
    "    ], axis=0\n",
    "    )\n",
    "    return loss_fcn(labels, scores)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = tf.concat([pos_score, neg_score], axis=0).numpy()\n",
    "    labels = tf.concat([\n",
    "        tf.ones(pos_score.shape[0]),\n",
    "        tf.zeros(neg_score.shape[0])\n",
    "    ], axis=0).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d214876",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    in_feat = train_g.ndata[\"feat\"]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        h = model(in_feat)\n",
    "        pos_score = pred(train_pos_g, h)\n",
    "        neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    val_pos_score = pred(val_pos_g, h)\n",
    "    val_neg_score = pred(val_neg_g, h)\n",
    "    val_auc = compute_auc(val_pos_score, val_neg_score)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch {:3d} | train_loss: {:.3f}, val_auc: {:.3f}\".format(epoch, loss, val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = tf.stop_gradient(pred(test_pos_g, h))\n",
    "neg_score = tf.stop_gradient(pred(test_neg_g, h))\n",
    "print('Test AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a6da9",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
