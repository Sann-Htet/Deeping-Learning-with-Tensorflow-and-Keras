{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b83b9f0",
      "metadata": {
        "id": "9b83b9f0"
      },
      "source": [
        "# Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4d5f673f",
      "metadata": {
        "id": "4d5f673f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, preprocessing\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "306dc70d",
      "metadata": {
        "id": "306dc70d"
      },
      "outputs": [],
      "source": [
        "max_len = 200\n",
        "n_words = 10000\n",
        "dim_embedding = 256\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8d1766d2",
      "metadata": {
        "id": "8d1766d2"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    # Load data\n",
        "    (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
        "    # Pad sequences with max_len\n",
        "    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d18a37b8",
      "metadata": {
        "id": "d18a37b8"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    # Input: - eEmbedding Layer.\n",
        "    # The model will take as input an integer matrix of size (batch, input_length).\n",
        "    # The model will output dimension (input_length, dim_embedding).\n",
        "    # The largest integer in the input should be no larger\n",
        "    # than n_words (vocabulary size).\n",
        "    model.add(layers.Embedding(n_words, dim_embedding, input_length=max_len))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    # Takes the maximum value of either feature vector from each of the n_words features.\n",
        "    model.add(layers.GlobalMaxPool1D())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6d71b10",
      "metadata": {
        "id": "a6d71b10"
      },
      "source": [
        "Now we need to train our model and this piece of code is very similar to what we have done with\n",
        "`MNIST`. Letâ€™s see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e702f64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e702f64",
        "outputId": "9b8ef5ff-d98d-43a6-f18b-eb1b1c830bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_data()\n",
        "model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ac3d2eaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3d2eaa",
        "outputId": "1e38abeb-437e-4088-bc7b-6bfb277cb60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 256)          2560000   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 256)          0         \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,593,025\n",
            "Trainable params: 2,593,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "df349267",
      "metadata": {
        "id": "df349267"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "87f7eb52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f7eb52",
        "outputId": "ec16c433-3a02-4133-bb6e-a93e2da8b6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 17s 215ms/step - loss: 0.6724 - accuracy: 0.6111 - val_loss: 0.6345 - val_accuracy: 0.7810\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 9s 182ms/step - loss: 0.4714 - accuracy: 0.8376 - val_loss: 0.3743 - val_accuracy: 0.8544\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.2877 - accuracy: 0.8844 - val_loss: 0.3118 - val_accuracy: 0.8704\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.2230 - accuracy: 0.9134 - val_loss: 0.2959 - val_accuracy: 0.8755\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 5s 110ms/step - loss: 0.1754 - accuracy: 0.9364 - val_loss: 0.2906 - val_accuracy: 0.8752\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.1385 - accuracy: 0.9530 - val_loss: 0.2931 - val_accuracy: 0.8727\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.3032 - val_accuracy: 0.8707\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.0799 - accuracy: 0.9772 - val_loss: 0.3257 - val_accuracy: 0.8624\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0618 - accuracy: 0.9830 - val_loss: 0.3397 - val_accuracy: 0.8597\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.0465 - accuracy: 0.9880 - val_loss: 0.3498 - val_accuracy: 0.8592\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.0335 - accuracy: 0.9930 - val_loss: 0.3665 - val_accuracy: 0.8566\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0260 - accuracy: 0.9954 - val_loss: 0.3857 - val_accuracy: 0.8559\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.4004 - val_accuracy: 0.8542\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0163 - accuracy: 0.9974 - val_loss: 0.4187 - val_accuracy: 0.8540\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.4378 - val_accuracy: 0.8528\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 0.4466 - val_accuracy: 0.8509\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.4656 - val_accuracy: 0.8506\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 2s 33ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.4771 - val_accuracy: 0.8506\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 2s 33ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.4901 - val_accuracy: 0.8506\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.5021 - val_accuracy: 0.8495\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7aa3fd76a5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.fit(X_train, y_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEKoMtn2NfG5",
        "outputId": "c9480436-0119-4570-a56b-aa90a3b33ac2"
      },
      "id": "nEKoMtn2NfG5",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.8495\n",
            "\n",
            "Test score: 0.5021467208862305\n",
            "Test accuracy: 0.8495200276374817\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}